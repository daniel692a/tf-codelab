{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HelloML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7UZcmZ7f4hIqOierpKJyx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel692a/tf-codelab/blob/main/HelloML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfPP0-zFHIvi"
      },
      "source": [
        "# What is ML?\n",
        "En la programación tradicional, expresas reglas por medio de un lenguaje de programación, estas reglas actúan sobre los datos de entrada para después dar una respuesta. El proceso en Machine Learning es muy similar, pero los ejes no."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTav7O2dIOBA"
      },
      "source": [
        "En vez de expresar las reglas, lo que provees son las respuestas (típicamente se llaman labels) junto con los datos, con ello la máquina infiere las reglas que determina la relación con los datos y las respuestas.\n",
        "Se recopila gran cantidad de datos y los etiqueta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdXCcLkIJOmL"
      },
      "source": [
        "El ML tiene ventajas al no solo limitarse a unos escenarios como lo hace la programación  tradicional, si no a crear nuevos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzDklKWnJw6a"
      },
      "source": [
        "## Programa vs Modelo\n",
        "En programación al compilar el código a binario se crea un programa, en ML lo que se crea con etiquetas y datos, se llama modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJAx7ZZFKfEL"
      },
      "source": [
        "## Your First ML model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1otbM831HE8_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Jun9i8Le2g"
      },
      "source": [
        "### Neuronal Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb2LhBkVLb54"
      },
      "source": [
        "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Pib6WaNl6s"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auqVWu-NN2G-"
      },
      "source": [
        "### Provide Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBEbff_GNyRq"
      },
      "source": [
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-2.0, 1.0, 4.0, 7.0, 10.0, 13.0], dtype=float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDsat88iOjVx"
      },
      "source": [
        "## Train the Neuronal Network\n",
        "> El proceso de entrenamiento de la red neuronal, donde aprende la relación entre las X y las Y, se encuentra en la llamada `model.fit`. Ahí es donde pasará por el ciclo antes de hacer una suposición, medir qué tan bueno o malo es (la pérdida), o usar el optimizador para hacer otra suposición. Lo hará por el número de épocas que especifique. Cuando ejecute ese código, verá que la pérdida se imprimirá para cada época."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUQeYcuBOin1",
        "outputId": "6c6c5f72-d086-4e44-995c-a93ae40d7124"
      },
      "source": [
        "model.fit(xs, ys, epochs=47)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9363e-06\n",
            "Epoch 2/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8760e-06\n",
            "Epoch 3/47\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8165e-06\n",
            "Epoch 4/47\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7590e-06\n",
            "Epoch 5/47\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7022e-06\n",
            "Epoch 6/47\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6464e-06\n",
            "Epoch 7/47\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5922e-06\n",
            "Epoch 8/47\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5387e-06\n",
            "Epoch 9/47\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4865e-06\n",
            "Epoch 10/47\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4353e-06\n",
            "Epoch 11/47\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3852e-06\n",
            "Epoch 12/47\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3364e-06\n",
            "Epoch 13/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2885e-06\n",
            "Epoch 14/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2415e-06\n",
            "Epoch 15/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1951e-06\n",
            "Epoch 16/47\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1503e-06\n",
            "Epoch 17/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1059e-06\n",
            "Epoch 18/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0629e-06\n",
            "Epoch 19/47\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0204e-06\n",
            "Epoch 20/47\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9790e-06\n",
            "Epoch 21/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9383e-06\n",
            "Epoch 22/47\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8984e-06\n",
            "Epoch 23/47\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8595e-06\n",
            "Epoch 24/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8215e-06\n",
            "Epoch 25/47\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7841e-06\n",
            "Epoch 26/47\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7474e-06\n",
            "Epoch 27/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7115e-06\n",
            "Epoch 28/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6764e-06\n",
            "Epoch 29/47\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6420e-06\n",
            "Epoch 30/47\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6083e-06\n",
            "Epoch 31/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5753e-06\n",
            "Epoch 32/47\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5431e-06\n",
            "Epoch 33/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5113e-06\n",
            "Epoch 34/47\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4803e-06\n",
            "Epoch 35/47\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4499e-06\n",
            "Epoch 36/47\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4200e-06\n",
            "Epoch 37/47\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3909e-06\n",
            "Epoch 38/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3623e-06\n",
            "Epoch 39/47\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3344e-06\n",
            "Epoch 40/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3068e-06\n",
            "Epoch 41/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2800e-06\n",
            "Epoch 42/47\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2538e-06\n",
            "Epoch 43/47\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2281e-06\n",
            "Epoch 44/47\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2028e-06\n",
            "Epoch 45/47\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1780e-06\n",
            "Epoch 46/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1539e-06\n",
            "Epoch 47/47\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1301e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa35086edd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhAEhHQvPhei"
      },
      "source": [
        "En este proceso de entrenamiento se puede observar que la pérdida esta disminuyendo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN5rNPvwP0G3"
      },
      "source": [
        "## Use the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2__D4Vm5P2KX"
      },
      "source": [
        "Después de entrenar al modelo, podemos usarlo para predecir un valor, con la función `model.predict`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZatzuAgQIgv",
        "outputId": "2e3ecb01-2141-4d4d-f9fe-934e6ed26896"
      },
      "source": [
        "print(model.predict([10.0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[30.9969]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbmI7I90QRQ0"
      },
      "source": [
        "Es un valor bastante cercano a 31, las redes neuronales tratan con probabilidades, por lo que calculó que hay una probabilidad muy alta de que la relación entre X e Y sea Y = 3X + 1, pero no puede saberlo con certeza con solo seis puntos de datos. El resultado está muy cerca de 31, pero no necesariamente 31.\n",
        "\n",
        "A medida que trabaje con redes neuronales, verá que ese patrón se repite. Casi siempre se ocupará de probabilidades, no de certezas, y codificará un poco para averiguar cuál es el resultado en función de las probabilidades, especialmente cuando se trata de clasificación."
      ]
    }
  ]
}